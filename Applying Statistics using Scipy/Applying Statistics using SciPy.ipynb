{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c11783a9",
   "metadata": {},
   "source": [
    "## 1.\tDefine and briefly elaborate Central Tendency using measures with examples?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9a537c",
   "metadata": {},
   "source": [
    "Central tendency is a statistic that represents the single value of the entire population or a dataset. Some of the important examples of central tendency include mode, median, and mean.\n",
    "\n",
    "**Mean :** is the average of all the numbers in a dataset. It is calculated by adding up all the numbers and dividing by the total number of numbers. For example, if you have the numbers 1, 2, 3, 4, and 5, the mean is 3.\n",
    "\n",
    "**Median :** is the middle number in a dataset when the numbers are arranged in order from least to greatest. For example, if you have the numbers 1, 2, 3, 4, and 5, the median is 3.\n",
    "\n",
    "**Mode :** is the number that occurs most often in a dataset. For example, if you have the numbers 1, 1, 2, 3, 4, and 5, the mode is 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f712c0",
   "metadata": {},
   "source": [
    "## 2.\tWhat do you understand by the empirical rule of normal distribution? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854475ab",
   "metadata": {},
   "source": [
    "The empirical rule, also known as the 68-95-99.7 rule, is a statistical rule that describes where most values lie in a normal distribution. It states that: \n",
    " - 68% of data points will fall within one standard deviation of the mean\n",
    " - 95% of data points will fall within two standard deviations of the mean\n",
    " - 99.7% of data points will fall within three standard deviations of the mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21f5424",
   "metadata": {},
   "source": [
    "## 3.\tDescribe the Hypothesis Testing and why do we conduct it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1328aa20",
   "metadata": {},
   "source": [
    "**Hypothesis Testing:**\n",
    "\n",
    "Hypothesis testing is a statistical method used to make inferences about a population based on a sample of data. The process involves formulating a hypothesis, collecting and analyzing data, and drawing conclusions about the population based on the analysis. The two main types of hypotheses in hypothesis testing are the null hypothesis (H0) and the alternative hypothesis (H1 or Ha).\n",
    "\n",
    "1. **Null Hypothesis (H0):**\n",
    "   - The null hypothesis is a statement that there is no significant difference or effect. It represents a default or baseline assumption.\n",
    "   - Example: H0: There is no difference in the average test scores between Group A and Group B.\n",
    "\n",
    "2. **Alternative Hypothesis (H1 or Ha):**\n",
    "   - The alternative hypothesis is a statement that contradicts the null hypothesis and suggests the presence of a significant difference or effect.\n",
    "   - Example: Ha: There is a significant difference in the average test scores between Group A and Group B.\n",
    "\n",
    "**Steps in Hypothesis Testing:**\n",
    "\n",
    "1. State your null and alternate hypothesis\n",
    "2. Collect data\n",
    "3. Perform a statistical test\n",
    "4. Decide whether to reject or fail to reject your null hypothesis\n",
    "5. Present findings\n",
    "\n",
    "Overall, hypothesis testing allows researchers and decision-makers to draw conclusions about populations based on limited but carefully collected and analyzed data, providing a basis for informed decision-making and advancing scientific knowledge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a1292a",
   "metadata": {},
   "source": [
    "## 4.\tWhat is the difference between Type-I and Type-II error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70f9aee",
   "metadata": {},
   "source": [
    "**Type I Error:**\n",
    "- **Definition:** Incorrectly rejecting a true null hypothesis.\n",
    "- **Symbol:** \\( \\alpha \\) (significance level).\n",
    "- **Example:** Incorrectly concluding a treatment is effective when it is not.\n",
    "\n",
    "**Type II Error:**\n",
    "- **Definition:** Incorrectly failing to reject a false null hypothesis.\n",
    "- **Symbol:** \\( \\beta \\).\n",
    "- **Example:** Incorrectly concluding a treatment is not effective when it is.\n",
    "\n",
    "In short, Type I is a false positive (detecting an effect that isn't there), and Type II is a false negative (missing a real effect)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc76109",
   "metadata": {},
   "source": [
    "## 5.\tWhat are Confidence Interval, Significant Level and P-Value?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467a627d",
   "metadata": {},
   "source": [
    "1. **Confidence Interval:**\n",
    "   - A range of values estimating the true parameter with a certain level of confidence.\n",
    "   - Example: A 95% confidence interval for average height is 65-75 inches.\n",
    "\n",
    "2. **Significance Level (α):**\n",
    "   - Probability of rejecting the null hypothesis when it is true, typically set at 0.05.\n",
    "   - Example: If p-value < 0.05, reject the null hypothesis.\n",
    "\n",
    "3. **P-Value:**\n",
    "   - Probability of observing a test statistic as extreme as the one in the data, assuming the null hypothesis is true.\n",
    "   - Example: P-value of 0.03 suggests strong evidence to reject the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b89b61b",
   "metadata": {},
   "source": [
    "## 6.\tList the differences between Parametric and Non Parametric Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203e9a81",
   "metadata": {},
   "source": [
    "1. **Assumptions:**\n",
    "   - **Parametric:** Assumes specific population distribution (e.g., normal) and parameters (e.g., mean).\n",
    "   - **Nonparametric:** Does not assume a specific population distribution or parameters.\n",
    "\n",
    "2. **Type of Data:**\n",
    "   - **Parametric:** Typically used for interval or ratio scale data.\n",
    "   - **Nonparametric:** More flexible, applicable to ordinal or nominal scale data.\n",
    "\n",
    "3. **Power:**\n",
    "   - **Parametric:** Generally more powerful with larger sample sizes and when assumptions are met.\n",
    "   - **Nonparametric:** Tends to be less powerful, especially with small sample sizes.\n",
    "\n",
    "4. **Precision:**\n",
    "   - **Parametric:** Provides more precise estimates of population parameters under assumptions.\n",
    "   - **Nonparametric:** Provides less precise estimates of population parameters.\n",
    "\n",
    "5. **Examples:**\n",
    "   - **Parametric:** t-Test, ANOVA, Pearson correlation, linear regression.\n",
    "   - **Nonparametric:** Mann-Whitney U test, Wilcoxon signed-rank test, Kruskal-Wallis, Spearman's rank correlation.\n",
    "\n",
    "6. **Application:**\n",
    "   - **Parametric:** Applied when data meet distributional assumptions.\n",
    "   - **Nonparametric:** Applied when data do not meet distributional assumptions or with ordinal/nominal data.\n",
    "\n",
    "7. **Sensitivity to Outliers:**\n",
    "   - **Parametric:** Sensitive to outliers.\n",
    "   - **Nonparametric:** Less sensitive to outliers.\n",
    "\n",
    "8. **Complexity:**\n",
    "   - **Parametric:** More complex in assumptions and calculations.\n",
    "   - **Nonparametric:** Simpler in assumptions and calculations.\n",
    "\n",
    "9. **Usage:**\n",
    "   - **Parametric:** Common in well-controlled experiments with met assumptions.\n",
    "   - **Nonparametric:** Used when dealing with real-world data or violated assumptions.\n",
    "\n",
    "10. **Post Hoc Tests:**\n",
    "    - **Parametric:** Often accompanied by post hoc tests for specific group differences.\n",
    "    - **Nonparametric:** Post hoc tests less common, pairwise comparisons may be simpler."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ce210b",
   "metadata": {},
   "source": [
    "## 7.\tWhat is Central Limit Theorem "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca723b92",
   "metadata": {},
   "source": [
    "**The Central Limit Theorem :** is a fundamental concept in statistics that describes the shape of the sampling distribution of the sample mean (or other sample statistics) when drawing repeated random samples from a population, regardless of the shape of the population distribution. It is particularly powerful because it allows statisticians to make certain probabilistic statements about the sample mean, even when the population distribution is unknown or non-normal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694d7bd6",
   "metadata": {},
   "source": [
    "## 8.\tFind the probability of P(x<400) given that mean is = 1000 variance is =100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f3e1f3",
   "metadata": {},
   "source": [
    "To find the probability P(x < 400) given a mean of 1000 and a variance of 100, we can use the standard normal distribution.\n",
    "\n",
    "First, we need to standardize the value of 400 using the formula:\n",
    "\n",
    "Z = (X - μ) / σ\n",
    "\n",
    "**Where:**\n",
    "\n",
    " - Z is the standardized value\n",
    " - X is the given value (400 in this case)\n",
    " - μ is the mean (1000 in this case)\n",
    " - σ is the standard deviation (square root of the variance, which is 10 in this case)\n",
    "**Plugging in the values, we get:**\n",
    "\n",
    "Z = (400 - 1000) / 10 Z = -60\n",
    "\n",
    "Next, we need to find the cumulative probability up to the standardized value Z using a standard normal distribution table or a calculator. The cumulative probability represents the area under the curve up to Z.\n",
    "\n",
    "Looking up the value of -60 in the standard normal distribution table, we find that the cumulative probability is approximately 0.\n",
    "\n",
    "Therefore, the probability P(x < 400) is approximately 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1362e8",
   "metadata": {},
   "source": [
    "## 9.\tProvide a proper description as to when to apply z-test, t-test, Chi-Square and Annona, with examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1352532e",
   "metadata": {},
   "source": [
    "1. **Z-Test:**\n",
    "   - **When to use:**\n",
    "     - The population standard deviation is known.\n",
    "     - Sample size is large (typically n > 30).\n",
    "\n",
    "   - **Example:**\n",
    "     - You want to test if the average height of a sample of students is significantly different from the known average height of the entire student population.\n",
    "\n",
    "2. **T-Test:**\n",
    "   - **When to use:**\n",
    "     - The population standard deviation is unknown.\n",
    "     - Sample size is small (typically n < 30).\n",
    "     - Used for comparing the means of two independent groups (independent t-test) or paired observations (paired t-test).\n",
    "\n",
    "   - **Example:**\n",
    "     - Independent t-test: Comparing the average scores of two groups of students who were taught by different teaching methods.\n",
    "     - Paired t-test: Testing if there is a significant difference in the blood pressure of individuals before and after treatment.\n",
    "\n",
    "3. **Chi-Square Test:**\n",
    "   - **When to use:**\n",
    "     - Used for categorical data.\n",
    "     - Tests the association between two categorical variables.\n",
    "\n",
    "   - **Example:**\n",
    "     - Testing whether there is a significant association between gender (male/female) and smoking status (smoker/non-smoker) in a population.\n",
    "\n",
    "4. **ANOVA (Analysis of Variance):**\n",
    "   - **When to use:**\n",
    "     - Used to compare means of three or more groups.\n",
    "     - Assumes that the data is normally distributed and variances are homogenous.\n",
    "\n",
    "   - **Example:**\n",
    "     - Testing if there is a significant difference in the average scores of students across three different teaching methods.\n",
    "\n",
    "In summary:\n",
    "- Use a **z-test** when you know the population standard deviation and have a large sample size.\n",
    "- Use a **t-test** when the population standard deviation is unknown and the sample size is small.\n",
    "- Use a **Chi-Square test** when dealing with categorical data and assessing the association between two categorical variables.\n",
    "- Use **ANOVA** when comparing means across three or more groups. If ANOVA indicates a significant difference, post-hoc tests (e.g., Tukey's HSD) can be used to identify which groups are different from each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f950bee",
   "metadata": {},
   "source": [
    "## 10.\tExplain the Bayes Theorem using an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d78f28",
   "metadata": {},
   "source": [
    "**Bayes' Theorem:**\n",
    "\n",
    "Bayes' theorem is a mathematical formula that describes the probability of an event, based on prior knowledge of conditions that might be related to the event. It is used in a wide variety of fields, including statistics, machine learning, and artificial intelligence.\n",
    "\n",
    "**Formula:**\n",
    "\n",
    " - P(A|B) = (P(B|A) * P(A)) / P(B)\n",
    "\n",
    " - P(A|B): Probability of event A occurring given that event B has already occurred (posterior probability)\n",
    "\n",
    " - P(B|A): Probability of event B occurring given that event A has already occurred (likelihood)\n",
    "\n",
    " - P(A): Prior probability of event A occurring (before considering evidence B)\n",
    "\n",
    " - P(B): Prior probability of event B occurring (total probability of B)\n",
    " \n",
    " **Scenario:** You have two bowls of cookies. Bowl A has 30 chocolate chip cookies and 10 oatmeal cookies. Bowl B has 20 chocolate chip cookies and 20 oatmeal cookies. You randomly select a bowl and then randomly pick a cookie from that bowl. The cookie turns out to be chocolate chip. What's the probability that you chose Bowl A?\n",
    "\n",
    "**Applying Bayes' Theorem:**\n",
    "\n",
    "- P(A|Chocolate Chip) = (P(Chocolate Chip|A) * P(A)) / P(Chocolate Chip)\n",
    "- P(Chocolate Chip|A) = 30/40 = 0.75 (probability of picking chocolate chip from Bowl A)\n",
    "- P(A) = 0.5 (equal chance of choosing either bowl)\n",
    "- P(Chocolate Chip) = P(Chocolate Chip|A) * P(A) + P(Chocolate Chip|B) * P(B) = 0.75 * 0.5 + 0.5 * 0.5 = 0.625\n",
    "- Plugging in the values: P(A|Chocolate Chip) = (0.75 * 0.5) / 0.625 = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a59062",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
